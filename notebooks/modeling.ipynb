{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Detection Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/smlovullo2304/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/smlovullo2304/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/smlovullo2304/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import raw data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/SMSSpamCollection.txt', 'r') as file_stream:\n",
    "    sms_messages_raw = file_stream.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect labels and messages from imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [re.search(\"(^.*)\\t\", message).group(1) for message in sms_messages_raw]\n",
    "sms_messages = [message[message.index('\\t')+1:-1] for message in sms_messages_raw]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitch the data together in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df = pd.DataFrame(data={'Labels': labels, 'Messages': sms_messages})\n",
    "messages_df['Labels'] = messages_df['Labels'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punc_count(s: str) -> int:\n",
    "    count = 0\n",
    "    for char in s:\n",
    "        count += 1 if char in string.punctuation else 0\n",
    "    return count\n",
    "\n",
    "def get_numeric_count(s: str) -> int:\n",
    "    count = 0\n",
    "    tokens = word_tokenize(s)\n",
    "    for word in tokens:\n",
    "        count += 1 if word.isnumeric() else 0\n",
    "    return count\n",
    "\n",
    "def get_uppercase_count(s: str) -> int:\n",
    "    count = 0\n",
    "    for char in s:\n",
    "        count += 1 if char.isupper() else 0\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset of various countable features from SMS Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {\n",
    "    'character_counts': [],\n",
    "    'punc_counts': [],\n",
    "    'numeric_counts': [],\n",
    "    'uppercase_counts': []\n",
    "}\n",
    "for message in messages_df['Messages']:\n",
    "    counts_dict['character_counts'].append(len(message))\n",
    "    counts_dict['punc_counts'].append(get_punc_count(message))\n",
    "    counts_dict['numeric_counts'].append(get_numeric_count(message))\n",
    "    counts_dict['uppercase_counts'].append(get_uppercase_count(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>character_counts</th>\n",
       "      <th>punc_counts</th>\n",
       "      <th>numeric_counts</th>\n",
       "      <th>uppercase_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels  character_counts  punc_counts  numeric_counts  uppercase_counts\n",
       "0          0               111            9               0                 3\n",
       "1          0                29            6               0                 2\n",
       "2          1               155            6               3                10\n",
       "3          0                49            6               0                 2\n",
       "4          0                61            2               0                 2\n",
       "...      ...               ...          ...             ...               ...\n",
       "5569       1               160            8               3                 9\n",
       "5570       0                36            1               0                 1\n",
       "5571       0                57            7               0                 2\n",
       "5572       0               125            1               0                 2\n",
       "5573       0                26            1               0                 2\n",
       "\n",
       "[5574 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df = messages_df[['Labels']].join(pd.DataFrame(counts_dict))\n",
    "counts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 1: Building Models Using String Feature Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = counts_df.drop(labels=['Labels'], axis=1)\n",
    "y = counts_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {'k_folds': n_splits, 'metrics': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9031161138037073 and its std: 0.005495514396836686\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.5498761511300105 and its std: 0.025538791597159535\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    # remove outliers for logistic regression training\n",
    "    indices_with_outliars = set()\n",
    "    for index in X_train[X_train['character_counts'] > X_train['character_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['punc_counts'] > X_train['punc_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['numeric_counts'] > X_train['numeric_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['uppercase_counts'] > X_train['uppercase_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    indices_with_outliars = list(indices_with_outliars)\n",
    "\n",
    "    clf_lr.fit(X_train.drop(labels=indices_with_outliars, axis=0), y_train.drop(labels=indices_with_outliars, axis=0))\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9446052452778911 and its std: 0.007795479410800483\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.7990096277181007 and its std: 0.025899539177808233\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.910294273074542 and its std: 0.003936748625486309\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6491286899227834 and its std: 0.026152021965490553\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multinomial Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=13)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9093964055100079 and its std: 0.011244653382689313\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6457398827758349 and its std: 0.0416740246792815\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('scale', RobustScaler()),\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.955595063741551 and its std: 0.006825329726119994\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8158899147953942 and its std: 0.027547681502392497\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9571643188235116 and its std: 0.0027073481205980555\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8268105723239625 and its std: 0.010917818147143508\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9580594182985813 and its std: 0.007169250330647891\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8348478747540483 and its std: 0.03286401898325739\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9562684644149517 and its std: 0.009023321874893403\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8341297145903652 and its std: 0.03129939647919094\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9594094910238409 and its std: 0.005680735615527291\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8364816758413353 and its std: 0.024233801042667244\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9555963219640349 and its std: 0.0075189103983331635\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8250229924446109 and its std: 0.03363168869030436\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: Gradient Boosting Classifier\n",
      "\tAverage Accuracy: 0.9594094910238409 with Standard Deviation: 0.005680735615527291\n",
      "\tAverage F1-Score: 0.8364816758413353 with Standard Deviation: 0.024233801042667244\n",
      "Model with best cv_f1_score: Gradient Boosting Classifier\n",
      "\tAverage Accuracy: 0.9594094910238409 with Standard Deviation: 0.005680735615527291\n",
      "\tAverage F1-Score: 0.8364816758413353 with Standard Deviation: 0.024233801042667244\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before hyperparameter tuning and by only using a dataset that contains various counted metrics about each sms message, it is possible to train a model with a high estimated accuracy and f1-score. Multiple runs of examining model cross-validation results found that the following models often performed better than the rest:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* XGBoost Classifier\n",
    "* Gradient Boosting Classifier\n",
    "* Extra Trees Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier more often outperformed the other models, so it was the chosen algorithm to construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classify__bootstrap': True, 'classify__max_features': 'sqrt', 'classify__min_samples_leaf': 1, 'classify__min_samples_split': 2, 'classify__n_estimators': 500}\n",
      "Best cross-validation score: 0.8488186232560245\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "param_grid = {\n",
    "    'classify__n_estimators': [50, 100, 250, 400, 500],\n",
    "    'classify__max_features': ['sqrt', 'log2'],\n",
    "    'classify__min_samples_split': [2, 5, 10],\n",
    "    'classify__min_samples_leaf': [1, 2, 4],\n",
    "    'classify__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[951  15]\n",
      " [ 24 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       966\n",
      "           1       0.89      0.84      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.91      0.92      1115\n",
      "weighted avg       0.96      0.97      0.96      1115\n",
      "\n",
      "Accuracy: 0.9650224215246637\n",
      "F1-Score: 0.8650519031141869\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier(\n",
    "        n_estimators=grid.best_params_['classify__n_estimators'],\n",
    "        max_features=grid.best_params_['classify__max_features'],\n",
    "        min_samples_split=grid.best_params_['classify__min_samples_split'],\n",
    "        min_samples_leaf=grid.best_params_['classify__min_samples_leaf'],\n",
    "        bootstrap=grid.best_params_['classify__bootstrap']\n",
    "    ))\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classify__learning_rate': 0.1, 'classify__max_depth': 3, 'classify__n_estimators': 150}\n",
      "Best cross-validation score: 0.8396048177490301\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "param_grid = {\n",
    "    'classify__n_estimators': [50, 100, 150],\n",
    "    'classify__learning_rate': [0.01, 0.1, 1],\n",
    "    'classify__max_depth': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[947  19]\n",
      " [ 25 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       966\n",
      "           1       0.87      0.83      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.92      0.91      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "Accuracy: 0.9605381165919282\n",
      "F1-Score: 0.8493150684931506\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier(\n",
    "        learning_rate=grid.best_params_['classify__learning_rate'],\n",
    "        n_estimators=grid.best_params_['classify__n_estimators'],\n",
    "        max_depth=grid.best_params_['classify__max_depth']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 2: Building Models Based on Word Content Using Count Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.punct_table = str.maketrans('', '', string.punctuation)\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.transformations = [\n",
    "            self._strip_punct,\n",
    "            self._convert_to_lowercase,\n",
    "            self._remove_stopwords,\n",
    "            self._remove_numbers,\n",
    "            self._remove_special_characters,\n",
    "            self._lemmatize\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def clean_text(self, X):\n",
    "        cleaned_text = []\n",
    "        for text in X:\n",
    "            for transformation in self.transformations:\n",
    "                text = transformation(text)\n",
    "            cleaned_text.append(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    def _strip_punct(self, text: str) -> str:\n",
    "        return text.translate(self.punct_table)\n",
    "\n",
    "    def _convert_to_lowercase(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def _remove_stopwords(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [w for w in words if w not in self.stopwords]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_numbers(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [w for w in words if not re.search(r'\\d', w)]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_special_characters(self, text: str) -> str:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def _lemmatize(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = messages_df[['Labels','Messages']]\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df['Messages']\n",
    "y = text_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {'k_folds': n_splits, 'metrics': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.957613000961282 and its std: 0.005471407807306032\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8139606254612863 and its std: 0.027601870294266553\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('normalize', Normalizer()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9475190369061819 and its std: 0.006580278723761395\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.7979445539217128 and its std: 0.02695581217757847\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9603035839209232 and its std: 0.004801481163606562\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8257880687618349 and its std: 0.02461974826260868\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multinomial Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=20)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9699483625492593 and its std: 0.0019296100013589\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8737314769701712 and its std: 0.009275010232237887\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('text_cleaner', TextCleaner()),\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('scale', RobustScaler(with_centering=False)),\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9748821045532555 and its std: 0.0015233037251525922\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.897413292655861 and its std: 0.006500453797215195\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9820592572461033 and its std: 0.0030880450019682903\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9294262803300576 and its std: 0.013069477234270873\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.974207445657371 and its std: 0.006232975088793353\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8932841777999251 and its std: 0.02835684799360344\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9739849919222117 and its std: 0.003431433899103548\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8944985584853645 and its std: 0.015588336041731963\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.960754027570171 and its std: 0.0023437170098915628\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8319414437487234 and its std: 0.013390609538186339\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9686038260029293 and its std: 0.005348017582151105\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8731281141412838 and its std: 0.023246521627147913\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9820592572461033 with Standard Deviation: 0.0030880450019682903\n",
      "\tAverage F1-Score: 0.9294262803300576 with Standard Deviation: 0.013069477234270873\n",
      "Model with best cv_f1_score: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9820592572461033 with Standard Deviation: 0.0030880450019682903\n",
      "\tAverage F1-Score: 0.9294262803300576 with Standard Deviation: 0.013069477234270873\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron neural network ultimately showed the most consistent best performance when constructing a model based on the word content of the sms messages. It will be chosen for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__activation': 'relu', 'classifier__alpha': 0.001, 'classifier__hidden_layer_sizes': (100,), 'classifier__learning_rate': 'constant', 'classifier__solver': 'adam'}\n",
      "Best cross-validation score: 0.9296886003484083\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__solver': ['adam'],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[961   5]\n",
      " [ 15 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       966\n",
      "           1       0.96      0.90      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Accuracy: 0.9820627802690582\n",
      "F1-Score: 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLPClassifier(\n",
    "        max_iter=1000,\n",
    "        hidden_layer_sizes=grid.best_params_['classifier__hidden_layer_sizes'],\n",
    "        activation=grid.best_params_['classifier__activation'],\n",
    "        solver=grid.best_params_['classifier__solver'],\n",
    "        alpha=grid.best_params_['classifier__alpha'],\n",
    "        learning_rate=grid.best_params_['classifier__learning_rate']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word-based model appears to perform better than the counts-based model. Let's examine the performance of models combining these two feature sets and see how they perform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 3: Combination of String Feature Counts and Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounter():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.count_types = [\n",
    "            CountTypes.CHAR,\n",
    "            CountTypes.PUNC,\n",
    "            CountTypes.NUM,\n",
    "            CountTypes.UPPER\n",
    "        ]\n",
    "        self.count_methods = [\n",
    "            self._get_char_count,\n",
    "            self._get_punc_count,\n",
    "            self._get_numeric_count,\n",
    "            self._get_uppercase_count\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.count_features(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.count_features(X)\n",
    "\n",
    "    def count_features(self, X):\n",
    "        # generates features dict to store values in lists organized by count type\n",
    "        features = {}\n",
    "        for count_type in self.count_types:\n",
    "            features[count_type] = []\n",
    "\n",
    "        # for each body of text, each count method is performed and values are stored in lists in the features dict organized by count type\n",
    "        for text in X:\n",
    "            for count_method in self.count_methods:\n",
    "                count_type, count_val = count_method(text)\n",
    "                features[count_type].append(count_val)\n",
    "\n",
    "        # converts dict into 2d list\n",
    "        features_as_2d_list = []\n",
    "        for count_vals in features.values():\n",
    "            features_as_2d_list.append(count_vals)\n",
    "\n",
    "        # returns array with data organized by row instead of by column\n",
    "        return np.array(features_as_2d_list).transpose()\n",
    "\n",
    "    def _get_char_count(self, s: str) -> int:\n",
    "        return (CountTypes.CHAR, len(s))\n",
    "\n",
    "    def _get_punc_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        for char in s:\n",
    "            count += 1 if char in string.punctuation else 0\n",
    "        return (CountTypes.PUNC, count)\n",
    "\n",
    "    def _get_numeric_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        tokens = word_tokenize(s)\n",
    "        for word in tokens:\n",
    "            count += 1 if word.isnumeric() else 0\n",
    "        return (CountTypes.NUM, count)\n",
    "\n",
    "    def _get_uppercase_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        for char in s:\n",
    "            count += 1 if char.isupper() else 0\n",
    "        return (CountTypes.UPPER, count)\n",
    "\n",
    "\n",
    "class CountTypes:\n",
    "    CHAR = 'char_count'\n",
    "    PUNC = 'punc_count'\n",
    "    NUM = 'numeric_count'\n",
    "    UPPER = 'upper_count'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.punct_table = str.maketrans('', '', string.punctuation)\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.transformations = [\n",
    "            self._strip_punct,\n",
    "            self._convert_to_lowercase,\n",
    "            self._remove_stopwords,\n",
    "            self._remove_numbers,\n",
    "            self._remove_special_characters,\n",
    "            self._lemmatize\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def clean_text(self, X):\n",
    "        cleaned_text = []\n",
    "        for text in X:\n",
    "            for transformation in self.transformations:\n",
    "                text = transformation(text)\n",
    "            cleaned_text.append(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    def _strip_punct(self, text: str) -> str:\n",
    "        return text.translate(self.punct_table)\n",
    "\n",
    "    def _convert_to_lowercase(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def _remove_stopwords(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if w not in self.stopwords]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_numbers(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if not re.search(r'\\d', w)]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_special_characters(self, text: str) -> str:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def _lemmatize(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts_pipe = Pipeline([\n",
    "    ('counter', TextCounter()),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "vectorizer_pipe = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.569767</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.383721</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081395</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.151163</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011628</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1.139535</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>-0.302326</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>-0.058140</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0.732558</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>-0.418605</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      char_count  punc_count  numeric_count  upper_count\n",
       "0       0.569767        1.50            0.0     0.333333\n",
       "1      -0.383721        0.75            0.0     0.000000\n",
       "2       1.081395        0.75            3.0     2.666667\n",
       "3      -0.151163        0.75            0.0     0.000000\n",
       "4      -0.011628       -0.25            0.0     0.000000\n",
       "...          ...         ...            ...          ...\n",
       "5569    1.139535        1.25            3.0     2.333333\n",
       "5570   -0.302326       -0.50            0.0    -0.333333\n",
       "5571   -0.058140        1.00            0.0     0.000000\n",
       "5572    0.732558       -0.50            0.0     0.000000\n",
       "5573   -0.418605       -0.50            0.0     0.000000\n",
       "\n",
       "[5574 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_feature_counts = pd.DataFrame(feature_counts_pipe.fit_transform(messages_df['Messages']), columns=[CountTypes.CHAR, CountTypes.PUNC, CountTypes.NUM, CountTypes.UPPER])\n",
    "str_feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathilove</th>\n",
       "      <th>aathiwhere</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 7614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aah  aaniye  aaooooright  aathilove  aathiwhere   ab  abbey   \n",
       "0     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0  \\\n",
       "1     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "2     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "3     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "4     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "...   ...  ...     ...          ...        ...         ...  ...    ...   \n",
       "5569  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5570  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5571  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5572  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5573  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "\n",
       "      abdomen  abeg  ...  zebra  zed  zero  zhong  zindgi  zoe  zogtorius   \n",
       "0         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0  \\\n",
       "1         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "2         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "3         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "4         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "...       ...   ...  ...    ...  ...   ...    ...     ...  ...        ...   \n",
       "5569      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5570      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5571      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5572      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5573      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "\n",
       "      zoom  zouk  zyada  \n",
       "0      0.0   0.0    0.0  \n",
       "1      0.0   0.0    0.0  \n",
       "2      0.0   0.0    0.0  \n",
       "3      0.0   0.0    0.0  \n",
       "4      0.0   0.0    0.0  \n",
       "...    ...   ...    ...  \n",
       "5569   0.0   0.0    0.0  \n",
       "5570   0.0   0.0    0.0  \n",
       "5571   0.0   0.0    0.0  \n",
       "5572   0.0   0.0    0.0  \n",
       "5573   0.0   0.0    0.0  \n",
       "\n",
       "[5574 rows x 7614 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(vectorizer_pipe.fit_transform(messages_df['Messages']).toarray(), columns=vectorizer_pipe.named_steps['vectorizer'].get_feature_names_out())\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = str_feature_counts.join(word_counts)\n",
    "y = messages_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9562682127704549 and its std: 0.008359373664032017\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8292108572756243 and its std: 0.03199913229674043\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9695014419229666 and its std: 0.004269172183391407\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8831848731406394 and its std: 0.017429786650813954\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.8824855430236596 and its std: 0.01000423966951353\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6565170645486595 and its std: 0.023798473321950585\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('classify', GaussianNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gaussian Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=9)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9324940989365503 and its std: 0.013638437071826843\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.7941413827877633 and its std: 0.03415718218810415\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9598521336936884 and its std: 0.009835475584386926\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8334421594734494 and its std: 0.04532670826393174\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9874409264543793 and its std: 0.003123829947718625\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9517370420860048 and its std: 0.012402514341603539\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9793666611304879 and its std: 0.0035230439313148126\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.916398806329908 and its std: 0.015494963354653805\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9773487239107569 and its std: 0.003283409197855285\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9079467322462392 and its std: 0.014082362105129118\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9746566310841347 and its std: 0.004180883451861918\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8989856626825181 and its std: 0.01779338809931539\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9771240053751263 and its std: 0.00392839316736369\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9108522042033937 and its std: 0.017396327304070192\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9874409264543793 with Standard Deviation: 0.003123829947718625\n",
      "\tAverage F1-Score: 0.9517370420860048 with Standard Deviation: 0.012402514341603539\n",
      "Model with best cv_f1_score: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9874409264543793 with Standard Deviation: 0.003123829947718625\n",
      "\tAverage F1-Score: 0.9517370420860048 with Standard Deviation: 0.012402514341603539\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__activation': 'relu', 'classifier__alpha': 0.001, 'classifier__hidden_layer_sizes': (50, 50), 'classifier__learning_rate': 'constant', 'classifier__solver': 'adam'}\n",
      "Best cross-validation score: 0.952645581406794\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('classifier', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__solver': ['adam'],\n",
    "    'classifier__alpha': [0.0001, 0.001],\n",
    "    'classifier__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[958   8]\n",
      " [ 10 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       966\n",
      "           1       0.95      0.93      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Accuracy: 0.9838565022421525\n",
      "F1-Score: 0.9391891891891893\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('classifier', MLPClassifier(\n",
    "        max_iter=1000,\n",
    "        hidden_layer_sizes=grid.best_params_['classifier__hidden_layer_sizes'],\n",
    "        activation=grid.best_params_['classifier__activation'],\n",
    "        solver=grid.best_params_['classifier__solver'],\n",
    "        alpha=grid.best_params_['classifier__alpha'],\n",
    "        learning_rate=grid.best_params_['classifier__learning_rate']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the counts-based model and the word-based model, the word-based model shows a better f1-score and accuracy. For the combined model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}