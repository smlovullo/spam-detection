{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Detection Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/smlovullo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/smlovullo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/smlovullo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import raw data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/SMSSpamCollection.txt', 'r') as file_stream:\n",
    "    sms_messages_raw = file_stream.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect labels and messages from imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [re.search(\"(^.*)\\t\", message).group(1) for message in sms_messages_raw]\n",
    "sms_messages = [message[message.index('\\t')+1:-1] for message in sms_messages_raw]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitch the data together in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its nam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                          Rofl. Its true to its nam\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df = pd.DataFrame(data={'Labels': labels, 'Messages': sms_messages})\n",
    "messages_df['Labels'] = messages_df['Labels'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punc_count(s: str) -> int:\n",
    "    count = 0\n",
    "    for char in s:\n",
    "        count += 1 if char in string.punctuation else 0\n",
    "    return count\n",
    "\n",
    "def get_numeric_count(s: str) -> int:\n",
    "    count = 0\n",
    "    tokens = word_tokenize(s)\n",
    "    for word in tokens:\n",
    "        count += 1 if word.isnumeric() else 0\n",
    "    return count\n",
    "\n",
    "def get_uppercase_count(s: str) -> int:\n",
    "    count = 0\n",
    "    for char in s:\n",
    "        count += 1 if char.isupper() else 0\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset of various countable features from SMS Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {\n",
    "    'character_counts': [],\n",
    "    'punc_counts': [],\n",
    "    'numeric_counts': [],\n",
    "    'uppercase_counts': []\n",
    "}\n",
    "for message in messages_df['Messages']:\n",
    "    counts_dict['character_counts'].append(len(message))\n",
    "    counts_dict['punc_counts'].append(get_punc_count(message))\n",
    "    counts_dict['numeric_counts'].append(get_numeric_count(message))\n",
    "    counts_dict['uppercase_counts'].append(get_uppercase_count(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>character_counts</th>\n",
       "      <th>punc_counts</th>\n",
       "      <th>numeric_counts</th>\n",
       "      <th>uppercase_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels  character_counts  punc_counts  numeric_counts  uppercase_counts\n",
       "0          0               111            9               0                 3\n",
       "1          0                29            6               0                 2\n",
       "2          1               155            6               3                10\n",
       "3          0                49            6               0                 2\n",
       "4          0                61            2               0                 2\n",
       "...      ...               ...          ...             ...               ...\n",
       "5569       1               160            8               3                 9\n",
       "5570       0                36            1               0                 1\n",
       "5571       0                57            7               0                 2\n",
       "5572       0               125            1               0                 2\n",
       "5573       0                25            1               0                 2\n",
       "\n",
       "[5574 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df = messages_df[['Labels']].join(pd.DataFrame(counts_dict))\n",
    "counts_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 1: Building Models Using String Feature Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = counts_df.drop(labels=['Labels'], axis=1)\n",
    "y = counts_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {'k_folds': n_splits, 'metrics': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9033405806948409 and its std: 0.005573357835380953\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.549485757930491 and its std: 0.03778797998883952\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    # remove outliers for logistic regression training\n",
    "    indices_with_outliars = set()\n",
    "    for index in X_train[X_train['character_counts'] > X_train['character_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['punc_counts'] > X_train['punc_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['numeric_counts'] > X_train['numeric_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    for index in X_train[X_train['uppercase_counts'] > X_train['uppercase_counts'].quantile(0.99)].index.to_list():\n",
    "        indices_with_outliars.add(index)\n",
    "    indices_with_outliars = list(indices_with_outliars)\n",
    "\n",
    "    clf_lr.fit(X_train.drop(labels=indices_with_outliars, axis=0), y_train.drop(labels=indices_with_outliars, axis=0))\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9441580730071013 and its std: 0.0066269627495905105\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.7892391638510784 and its std: 0.02646930932293095\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.909845339292275 and its std: 0.004168673996548207\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6484110463043381 and its std: 0.022972931667944056\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multinomial Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=15)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9105220113441339 and its std: 0.010546870688534165\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6533606765567294 and its std: 0.03517929137317372\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('scale', RobustScaler()),\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9564949444620595 and its std: 0.006540073041995297\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8185636050415142 and its std: 0.02968020532000147\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9580619347435491 and its std: 0.005242553316435197\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8314374510339206 and its std: 0.020066421662798938\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9569428716663395 and its std: 0.004721475912709519\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8326990322300594 and its std: 0.018401993010771493\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.955372358361895 and its std: 0.0035601586411803674\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8288901181033298 and its std: 0.012553233296701334\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9562664512589774 and its std: 0.00699617888979639\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8249177997671799 and its std: 0.03176069546929763\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9585106168813194 and its std: 0.00646126629165489\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8362791895717742 and its std: 0.024358836669605134\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: XGBoost Classifier\n",
      "\tAverage Accuracy: 0.9585106168813194 with Standard Deviation: 0.00646126629165489\n",
      "\tAverage F1-Score: 0.8362791895717742 with Standard Deviation: 0.024358836669605134\n",
      "Model with best cv_f1_score: XGBoost Classifier\n",
      "\tAverage Accuracy: 0.9585106168813194 with Standard Deviation: 0.00646126629165489\n",
      "\tAverage F1-Score: 0.8362791895717742 with Standard Deviation: 0.024358836669605134\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before hyperparameter tuning and by only using a dataset that contains various counted metrics about each sms message, it is possible to train a model with a high estimated accuracy and f1-score. Multiple runs of examining model cross-validation results found that the following models often performed better than the rest:\n",
    "\n",
    "* Random Forest Classifier\n",
    "* XGBoost Classifier\n",
    "* Gradient Boosting Classifier\n",
    "* Extra Trees Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier more often outperformed the other models, so it was the chosen algorithm to construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classify__bootstrap': True, 'classify__max_features': 'sqrt', 'classify__min_samples_leaf': 1, 'classify__min_samples_split': 2, 'classify__n_estimators': 500}\n",
      "Best cross-validation score: 0.8503556806032002\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "param_grid = {\n",
    "    'classify__n_estimators': [50, 100, 250, 400, 500],\n",
    "    'classify__max_features': ['sqrt', 'log2'],\n",
    "    'classify__min_samples_split': [2, 5, 10],\n",
    "    'classify__min_samples_leaf': [1, 2, 4],\n",
    "    'classify__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[953  13]\n",
      " [ 24 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       966\n",
      "           1       0.91      0.84      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.91      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Accuracy: 0.9668161434977578\n",
      "F1-Score: 0.8710801393728224\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', RandomForestClassifier(\n",
    "        n_estimators=grid.best_params_['classify__n_estimators'],\n",
    "        max_features=grid.best_params_['classify__max_features'],\n",
    "        min_samples_split=grid.best_params_['classify__min_samples_split'],\n",
    "        min_samples_leaf=grid.best_params_['classify__min_samples_leaf'],\n",
    "        bootstrap=grid.best_params_['classify__bootstrap']\n",
    "    ))\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classify__learning_rate': 0.1, 'classify__max_depth': 3, 'classify__n_estimators': 150}\n",
      "Best cross-validation score: 0.8396048177490301\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "param_grid = {\n",
    "    'classify__n_estimators': [50, 100, 150],\n",
    "    'classify__learning_rate': [0.01, 0.1, 1],\n",
    "    'classify__max_depth': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[947  19]\n",
      " [ 25 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       966\n",
      "           1       0.87      0.83      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.92      0.91      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "Accuracy: 0.9605381165919282\n",
      "F1-Score: 0.8493150684931506\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('scale', RobustScaler()),\n",
    "    ('classify', GradientBoostingClassifier(\n",
    "        learning_rate=grid.best_params_['classify__learning_rate'],\n",
    "        n_estimators=grid.best_params_['classify__n_estimators'],\n",
    "        max_depth=grid.best_params_['classify__max_depth']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 2: Building Models Based on Word Content Using Count Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.punct_table = str.maketrans('', '', string.punctuation)\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.transformations = [\n",
    "            self._strip_punct,\n",
    "            self._convert_to_lowercase,\n",
    "            self._remove_stopwords,\n",
    "            self._remove_numbers,\n",
    "            self._remove_special_characters,\n",
    "            self._lemmatize\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def clean_text(self, X):\n",
    "        cleaned_text = []\n",
    "        for text in X:\n",
    "            for transformation in self.transformations:\n",
    "                text = transformation(text)\n",
    "            cleaned_text.append(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    def _strip_punct(self, text: str) -> str:\n",
    "        return text.translate(self.punct_table)\n",
    "\n",
    "    def _convert_to_lowercase(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def _remove_stopwords(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [w for w in words if w not in self.stopwords]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_numbers(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [w for w in words if not re.search(r'\\d', w)]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_special_characters(self, text: str) -> str:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def _lemmatize(self, text: str) -> str:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its nam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                          Rofl. Its true to its nam\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = messages_df[['Labels','Messages']]\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_df['Messages']\n",
    "y = text_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {'k_folds': n_splits, 'metrics': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9558197822771813 and its std: 0.0036556890170207144\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8052251994736557 and its std: 0.019279604032540205\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('normalize', Normalizer()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.954475245730851 and its std: 0.009497171207188744\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.826114364268243 and its std: 0.039747133668020546\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9614271765990751 and its std: 0.003849860674290464\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8317583829316982 and its std: 0.019241701518066836\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', MultinomialNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multinomial Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=4)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9715186242092072 and its std: 0.002074758042888417\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8810973434797049 and its std: 0.0098913648133967\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('text_cleaner', TextCleaner()),\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('scale', RobustScaler(with_centering=False)),\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9744329191264918 and its std: 0.005995136631526237\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.895200928865399 and its std: 0.027362142586644163\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9811628995485497 and its std: 0.002952109087357548\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9255790975395456 and its std: 0.012047429218171818\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9717443493228247 and its std: 0.0063913030441011725\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8821780352132119 and its std: 0.02883904899863457\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9733123461823012 and its std: 0.004278087860989827\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8920377444929821 and its std: 0.01910041898827289\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9620993190499917 and its std: 0.0031206154519159697\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8404200870363232 and its std: 0.0158255603951531\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9668075875848672 and its std: 0.004180786756706938\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8650760033684426 and its std: 0.017893574576875144\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9811628995485497 with Standard Deviation: 0.002952109087357548\n",
      "\tAverage F1-Score: 0.9255790975395456 with Standard Deviation: 0.012047429218171818\n",
      "Model with best cv_f1_score: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9811628995485497 with Standard Deviation: 0.002952109087357548\n",
      "\tAverage F1-Score: 0.9255790975395456 with Standard Deviation: 0.012047429218171818\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptron neural network ultimately showed the most consistent best performance when constructing a model based on the word content of the sms messages. It will be chosen for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__activation': 'relu', 'classifier__alpha': 0.001, 'classifier__hidden_layer_sizes': (100,), 'classifier__learning_rate': 'constant', 'classifier__solver': 'adam'}\n",
      "Best cross-validation score: 0.9278587763005082\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__solver': ['adam'],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[959   7]\n",
      " [ 16 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       966\n",
      "           1       0.95      0.89      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Accuracy: 0.979372197309417\n",
      "F1-Score: 0.9204152249134949\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('text_cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MLPClassifier(\n",
    "        max_iter=1000,\n",
    "        hidden_layer_sizes=grid.best_params_['classifier__hidden_layer_sizes'],\n",
    "        activation=grid.best_params_['classifier__activation'],\n",
    "        solver=grid.best_params_['classifier__solver'],\n",
    "        alpha=grid.best_params_['classifier__alpha'],\n",
    "        learning_rate=grid.best_params_['classifier__learning_rate']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word-based model appears to perform better than the counts-based model. Let's examine the performance of models combining these two feature sets and see how they perform."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set 3: Combination of String Feature Counts and Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCounter():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.count_types = [\n",
    "            CountTypes.CHAR,\n",
    "            CountTypes.PUNC,\n",
    "            CountTypes.NUM,\n",
    "            CountTypes.UPPER\n",
    "        ]\n",
    "        self.count_methods = [\n",
    "            self._get_char_count,\n",
    "            self._get_punc_count,\n",
    "            self._get_numeric_count,\n",
    "            self._get_uppercase_count\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.count_features(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.count_features(X)\n",
    "\n",
    "    def count_features(self, X):\n",
    "        # generates features dict to store values in lists organized by count type\n",
    "        features = {}\n",
    "        for count_type in self.count_types:\n",
    "            features[count_type] = []\n",
    "\n",
    "        # for each body of text, each count method is performed and values are stored in lists in the features dict organized by count type\n",
    "        for text in X:\n",
    "            for count_method in self.count_methods:\n",
    "                count_type, count_val = count_method(text)\n",
    "                features[count_type].append(count_val)\n",
    "\n",
    "        # converts dict into 2d list\n",
    "        features_as_2d_list = []\n",
    "        for count_vals in features.values():\n",
    "            features_as_2d_list.append(count_vals)\n",
    "\n",
    "        # returns array with data organized by row instead of by column\n",
    "        return np.array(features_as_2d_list).transpose()\n",
    "\n",
    "    def _get_char_count(self, s: str) -> int:\n",
    "        return (CountTypes.CHAR, len(s))\n",
    "\n",
    "    def _get_punc_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        for char in s:\n",
    "            count += 1 if char in string.punctuation else 0\n",
    "        return (CountTypes.PUNC, count)\n",
    "\n",
    "    def _get_numeric_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        tokens = word_tokenize(s)\n",
    "        for word in tokens:\n",
    "            count += 1 if word.isnumeric() else 0\n",
    "        return (CountTypes.NUM, count)\n",
    "\n",
    "    def _get_uppercase_count(self, s: str) -> int:\n",
    "        count = 0\n",
    "        for char in s:\n",
    "            count += 1 if char.isupper() else 0\n",
    "        return (CountTypes.UPPER, count)\n",
    "\n",
    "\n",
    "class CountTypes:\n",
    "    CHAR = 'char_count'\n",
    "    PUNC = 'punc_count'\n",
    "    NUM = 'numeric_count'\n",
    "    UPPER = 'upper_count'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.punct_table = str.maketrans('', '', string.punctuation)\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.transformations = [\n",
    "            self._strip_punct,\n",
    "            self._convert_to_lowercase,\n",
    "            self._remove_stopwords,\n",
    "            self._remove_numbers,\n",
    "            self._remove_special_characters,\n",
    "            self._lemmatize\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.clean_text(X)\n",
    "\n",
    "    def clean_text(self, X):\n",
    "        cleaned_text = []\n",
    "        for text in X:\n",
    "            for transformation in self.transformations:\n",
    "                text = transformation(text)\n",
    "            cleaned_text.append(text)\n",
    "        return cleaned_text\n",
    "\n",
    "    def _strip_punct(self, text: str) -> str:\n",
    "        return text.translate(self.punct_table)\n",
    "\n",
    "    def _convert_to_lowercase(self, text: str) -> str:\n",
    "        return text.lower()\n",
    "\n",
    "    def _remove_stopwords(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if w not in self.stopwords]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_numbers(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [w for w in words if not re.search(r'\\d', w)]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def _remove_special_characters(self, text: str) -> str:\n",
    "        pattern = r'[^a-zA-Z0-9\\s]'\n",
    "        return re.sub(pattern, '', text)\n",
    "\n",
    "    def _lemmatize(self, text: str) -> str:\n",
    "        words = word_tokenize(text)\n",
    "        words = [self.lemmatizer.lemmatize(w) for w in words]\n",
    "        return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its nam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels                                           Messages\n",
       "0          0  Go until jurong point, crazy.. Available only ...\n",
       "1          0                      Ok lar... Joking wif u oni...\n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3          0  U dun say so early hor... U c already then say...\n",
       "4          0  Nah I don't think he goes to usf, he lives aro...\n",
       "...      ...                                                ...\n",
       "5569       1  This is the 2nd time we have tried 2 contact u...\n",
       "5570       0               Will ü b going to esplanade fr home?\n",
       "5571       0  Pity, * was in mood for that. So...any other s...\n",
       "5572       0  The guy did some bitching but I acted like i'd...\n",
       "5573       0                          Rofl. Its true to its nam\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counts_pipe = Pipeline([\n",
    "    ('counter', TextCounter()),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "vectorizer_pipe = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('vectorizer', TfidfVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>punc_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.569767</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.383721</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081395</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.151163</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011628</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1.139535</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>-0.302326</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>-0.058140</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0.732558</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>-0.430233</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      char_count  punc_count  numeric_count  upper_count\n",
       "0       0.569767        1.50            0.0     0.333333\n",
       "1      -0.383721        0.75            0.0     0.000000\n",
       "2       1.081395        0.75            3.0     2.666667\n",
       "3      -0.151163        0.75            0.0     0.000000\n",
       "4      -0.011628       -0.25            0.0     0.000000\n",
       "...          ...         ...            ...          ...\n",
       "5569    1.139535        1.25            3.0     2.333333\n",
       "5570   -0.302326       -0.50            0.0    -0.333333\n",
       "5571   -0.058140        1.00            0.0     0.000000\n",
       "5572    0.732558       -0.50            0.0     0.000000\n",
       "5573   -0.430233       -0.50            0.0     0.000000\n",
       "\n",
       "[5574 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_feature_counts = pd.DataFrame(feature_counts_pipe.fit_transform(messages_df['Messages']), columns=[CountTypes.CHAR, CountTypes.PUNC, CountTypes.NUM, CountTypes.UPPER])\n",
    "str_feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathilove</th>\n",
       "      <th>aathiwhere</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zed</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 7615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aah  aaniye  aaooooright  aathilove  aathiwhere   ab  abbey  \\\n",
       "0     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "1     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "2     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "3     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "4     0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "...   ...  ...     ...          ...        ...         ...  ...    ...   \n",
       "5569  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5570  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5571  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5572  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "5573  0.0  0.0     0.0          0.0        0.0         0.0  0.0    0.0   \n",
       "\n",
       "      abdomen  abeg  ...  zebra  zed  zero  zhong  zindgi  zoe  zogtorius  \\\n",
       "0         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "1         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "2         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "3         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "4         0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "...       ...   ...  ...    ...  ...   ...    ...     ...  ...        ...   \n",
       "5569      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5570      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5571      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5572      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "5573      0.0   0.0  ...    0.0  0.0   0.0    0.0     0.0  0.0        0.0   \n",
       "\n",
       "      zoom  zouk  zyada  \n",
       "0      0.0   0.0    0.0  \n",
       "1      0.0   0.0    0.0  \n",
       "2      0.0   0.0    0.0  \n",
       "3      0.0   0.0    0.0  \n",
       "4      0.0   0.0    0.0  \n",
       "...    ...   ...    ...  \n",
       "5569   0.0   0.0    0.0  \n",
       "5570   0.0   0.0    0.0  \n",
       "5571   0.0   0.0    0.0  \n",
       "5572   0.0   0.0    0.0  \n",
       "5573   0.0   0.0    0.0  \n",
       "\n",
       "[5574 rows x 7615 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(vectorizer_pipe.fit_transform(messages_df['Messages']).toarray(), columns=vectorizer_pipe.named_steps['vectorizer'].get_feature_names_out())\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = str_feature_counts.join(word_counts)\n",
    "y = messages_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=256)\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9567186564197028 and its std: 0.005946400640017153\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8300742304297934 and its std: 0.024064596528025995\n"
     ]
    }
   ],
   "source": [
    "clf_lr = Pipeline([\n",
    "    ('normalize', Normalizer()),\n",
    "    ('classify', LogisticRegression()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_lr.fit(X_train, y_train)\n",
    "    y_hat = clf_lr.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Logistic Regression Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9683818755567636 and its std: 0.010827017192441054\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8797614070890314 and its std: 0.04157707276971253\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('classify', DecisionTreeClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    y_hat = clf_dt.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Decision Tree Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.8878674638764323 and its std: 0.007923838736013692\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.6700361737936401 and its std: 0.016733896082594846\n"
     ]
    }
   ],
   "source": [
    "clf_nb = Pipeline([\n",
    "    ('classify', GaussianNB())\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_nb.fit(X_train, y_train)\n",
    "    y_hat = clf_nb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gaussian Naive Bayes Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier (k=17)\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9396697417624175 and its std: 0.0089747509318852\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8121912003883238 and its std: 0.022407584081356617\n"
     ]
    }
   ],
   "source": [
    "k_neighbor_min = 1\n",
    "k_neighbor_max = 20\n",
    "\n",
    "knn_classifier_results = {}\n",
    "max_accuracy = 0\n",
    "max_f1_score = 0 \n",
    "for k_neighbors in range(k_neighbor_min,k_neighbor_max+1):\n",
    "    clf_knn = Pipeline([\n",
    "        ('classify', KNeighborsClassifier(n_neighbors=k_neighbors)),\n",
    "    ])\n",
    "    cv_accuracies = np.array([])\n",
    "    cv_spam_f1_scores = np.array([])\n",
    "    for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "        X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "        y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "        clf_knn.fit(X_train, y_train)\n",
    "        y_hat = clf_nb.predict(X_val)\n",
    "        report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "        cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "        cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "    mean_accuracy = cv_accuracies.mean()\n",
    "    std_accuracy = cv_accuracies.std()\n",
    "    mean_f1_score = cv_spam_f1_scores.mean()\n",
    "    std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "    if max_accuracy <= mean_accuracy:\n",
    "        max_accuracy = mean_accuracy\n",
    "    if max_f1_score <= mean_f1_score:\n",
    "        max_f1_score = mean_f1_score\n",
    "\n",
    "    knn_classifier_results[k_neighbors] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "for k_neighbor_val, cv_results in knn_classifier_results.items():\n",
    "    if cv_results['cv_f1_score'] >= max_f1_score:\n",
    "        model_name = f\"K-Nearest Neighbors Classifier (k={k_neighbor_val})\"\n",
    "        model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "        print(model_name)\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {cv_results['cv_accuracy']} and its std: {cv_results['cv_accuracy_std']}\")\n",
    "        print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {cv_results['cv_f1_score']} and its std: {cv_results['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.960530063968031 and its std: 0.005728933805557085\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.837918426180339 and its std: 0.02331637087556264\n"
     ]
    }
   ],
   "source": [
    "clf_svc = Pipeline([\n",
    "    ('classify', SVC()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_svc.fit(X_train, y_train)\n",
    "    y_hat = clf_svc.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Support Vector Machine Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer Perceptron Neural Network Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9876663999235001 and its std: 0.004071133927362725\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9524897833935932 and its std: 0.016052730835191806\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = Pipeline([\n",
    "    ('classify', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_mlp.fit(X_train, y_train)\n",
    "    y_hat = clf_mlp.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Multilayer Perceptron Neural Network Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9789189855707046 and its std: 0.00681571742982477\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9139471134361077 and its std: 0.030059649983912855\n"
     ]
    }
   ],
   "source": [
    "clf_rf = Pipeline([\n",
    "    ('classify', RandomForestClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_hat = clf_rf.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Random Forest Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9780228795176479 and its std: 0.005139152486103386\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9102643024148309 and its std: 0.022691036130191477\n"
     ]
    }
   ],
   "source": [
    "clf_et = Pipeline([\n",
    "    ('classify', ExtraTreesClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_et.fit(X_train, y_train)\n",
    "    y_hat = clf_et.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Extra Trees Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9726384422199071 and its std: 0.00405762345823216\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.8921592127929671 and its std: 0.016251636084839222\n"
     ]
    }
   ],
   "source": [
    "clf_gb = Pipeline([\n",
    "    ('classify', GradientBoostingClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_gb.fit(X_train, y_train)\n",
    "    y_hat = clf_gb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"Gradient Boosting Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Stratified K-Fold (5) Cross Validation Average Accuracy: 0.9775736940908839 and its std: 0.0067256672755889564\n",
      "Stratified K-Fold (5) Cross Validation Average Spam F1-Score: 0.9126863716516876 and its std: 0.027409942803528563\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = Pipeline([\n",
    "    ('classify', XGBClassifier()),\n",
    "])\n",
    "cv_accuracies = np.array([])\n",
    "cv_spam_f1_scores = np.array([])\n",
    "for train_index, val_index in skf.split(X_train_full, y_train_full):\n",
    "    X_train, X_val = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
    "    y_train, y_val = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
    "\n",
    "    clf_xgb.fit(X_train, y_train)\n",
    "    y_hat = clf_xgb.predict(X_val)\n",
    "    report_results = classification_report(y_val, y_hat, output_dict=True)\n",
    "    cv_accuracies = np.append(cv_accuracies, report_results['accuracy'])\n",
    "    cv_spam_f1_scores = np.append(cv_spam_f1_scores, report_results['1']['f1-score'])\n",
    "\n",
    "mean_accuracy = cv_accuracies.mean()\n",
    "std_accuracy = cv_accuracies.std()\n",
    "mean_f1_score = cv_spam_f1_scores.mean()\n",
    "std_f1_score = cv_spam_f1_scores.std()\n",
    "\n",
    "model_name = \"XGBoost Classifier\"\n",
    "model_metrics['metrics'][model_name] = {'cv_accuracy': mean_accuracy, 'cv_accuracy_std': std_accuracy, 'cv_f1_score': mean_f1_score, 'cv_f1_score_std': std_f1_score}\n",
    "\n",
    "print(model_name)\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Accuracy: {mean_accuracy} and its std: {std_accuracy}\")\n",
    "print(f\"Stratified K-Fold ({n_splits}) Cross Validation Average Spam F1-Score: {mean_f1_score} and its std: {std_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with best cv_accuracy: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9876663999235001 with Standard Deviation: 0.004071133927362725\n",
      "\tAverage F1-Score: 0.9524897833935932 with Standard Deviation: 0.016052730835191806\n",
      "Model with best cv_f1_score: Multilayer Perceptron Neural Network Classifier\n",
      "\tAverage Accuracy: 0.9876663999235001 with Standard Deviation: 0.004071133927362725\n",
      "\tAverage F1-Score: 0.9524897833935932 with Standard Deviation: 0.016052730835191806\n"
     ]
    }
   ],
   "source": [
    "decision_scores = ['cv_accuracy', 'cv_f1_score']\n",
    "for score_type in decision_scores:\n",
    "    models_by_score = {}\n",
    "    for model_name, metrics in model_metrics['metrics'].items():\n",
    "        models_by_score[metrics[score_type]] = model_name\n",
    "    scores = np.array(list(models_by_score.keys()))\n",
    "    max_score = scores.max()\n",
    "    best_scoring_model_name = models_by_score[max_score]\n",
    "    print(f\"Model with best {score_type}: {best_scoring_model_name}\")\n",
    "    print(f\"\\tAverage Accuracy: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_accuracy_std']}\")\n",
    "    print(f\"\\tAverage F1-Score: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score']} with Standard Deviation: {model_metrics['metrics'][best_scoring_model_name]['cv_f1_score_std']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Pipeline([\n",
    "    ('classifier', MLPClassifier(max_iter=1000)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'classifier__activation': ['relu'],\n",
    "    'classifier__solver': ['adam'],\n",
    "    'classifier__alpha': [0.0001, 0.001],\n",
    "    'classifier__learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=n_splits, scoring='f1')\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[958   8]\n",
      " [ 10 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       966\n",
      "           1       0.95      0.93      0.94       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Accuracy: 0.9838565022421525\n",
      "F1-Score: 0.9391891891891893\n"
     ]
    }
   ],
   "source": [
    "classifier = Pipeline([\n",
    "    ('classifier', MLPClassifier(\n",
    "        max_iter=1000,\n",
    "        hidden_layer_sizes=grid.best_params_['classifier__hidden_layer_sizes'],\n",
    "        activation=grid.best_params_['classifier__activation'],\n",
    "        solver=grid.best_params_['classifier__solver'],\n",
    "        alpha=grid.best_params_['classifier__alpha'],\n",
    "        learning_rate=grid.best_params_['classifier__learning_rate']\n",
    "    )),\n",
    "])\n",
    "classifier.fit(X_train_full, y_train_full)\n",
    "y_hat = classifier.predict(X_test)\n",
    "report_results = classification_report(y_test, y_hat, output_dict=True)\n",
    "print(confusion_matrix(y_test, y_hat))\n",
    "print(classification_report(y_test, y_hat))\n",
    "print(f\"Accuracy: {report_results['accuracy']}\")\n",
    "print(f\"F1-Score: {report_results['1']['f1-score']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the counts-based model and the word-based model, the word-based model shows a better f1-score and accuracy. The combined model shows performance that is not different enough from the word-based model to warrant using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
